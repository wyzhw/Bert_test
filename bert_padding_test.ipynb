{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWLNrzM0Noqw"
      },
      "source": [
        "# Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OJR_RTQNoqy"
      },
      "source": [
        "Text classification is a common NLP task that assigns a label or class to text. Some of the largest companies run text classification in production for a wide range of practical applications. One of the most popular forms of text classification is sentiment analysis, which assigns a label like üôÇ positive, üôÅ negative, or üòê neutral to a sequence of text.\n",
        "\n",
        "This guide will show you how to:\n",
        "\n",
        "1. Finetune [DistilBERT](https://huggingface.co/distilbert-base-uncased) on the [IMDb](https://huggingface.co/datasets/imdb) dataset to determine whether a movie review is positive or negative.\n",
        "2. Use your finetuned model for inference.\n",
        "\n",
        "<Tip>\n",
        "The task illustrated in this tutorial is supported by the following model architectures:\n",
        "\n",
        "<!--This tip is automatically generated by `make fix-copies`, do not fill manually!-->\n",
        "\n",
        "[ALBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/albert), [BART](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bart), [BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bert), [BigBird](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/big_bird), [BigBird-Pegasus](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bigbird_pegasus), [BioGpt](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/biogpt), [BLOOM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bloom), [CamemBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/camembert), [CANINE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/canine), [ConvBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/convbert), [CTRL](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ctrl), [Data2VecText](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/data2vec-text), [DeBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/deberta), [DeBERTa-v2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/deberta-v2), [DistilBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/distilbert), [ELECTRA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/electra), [ERNIE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ernie), [ErnieM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ernie_m), [ESM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/esm), [FlauBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/flaubert), [FNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/fnet), [Funnel Transformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/funnel), [GPT-Sw3](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt-sw3), [OpenAI GPT-2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt2), [GPTBigCode](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_bigcode), [GPT Neo](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_neo), [GPT NeoX](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_neox), [GPT-J](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gptj), [I-BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ibert), [LayoutLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlm), [LayoutLMv2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlmv2), [LayoutLMv3](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlmv3), [LED](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/led), [LiLT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/lilt), [LLaMA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/llama), [Longformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/longformer), [LUKE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/luke), [MarkupLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/markuplm), [mBART](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mbart), [MEGA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mega), [Megatron-BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/megatron-bert), [MobileBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mobilebert), [MPNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mpnet), [MVP](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mvp), [Nezha](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nezha), [Nystr√∂mformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nystromformer), [OpenLlama](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/open-llama), [OpenAI GPT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/openai-gpt), [OPT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/opt), [Perceiver](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/perceiver), [PLBart](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/plbart), [QDQBert](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/qdqbert), [Reformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/reformer), [RemBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/rembert), [RoBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roberta), [RoBERTa-PreLayerNorm](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roberta-prelayernorm), [RoCBert](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roc_bert), [RoFormer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roformer), [SqueezeBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/squeezebert), [TAPAS](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/tapas), [Transformer-XL](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/transfo-xl), [XLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm), [XLM-RoBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm-roberta), [XLM-RoBERTa-XL](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm-roberta-xl), [XLNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlnet), [X-MOD](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xmod), [YOSO](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/yoso)\n",
        "\n",
        "\n",
        "<!--End of the generated tip-->\n",
        "\n",
        "</Tip>\n",
        "\n",
        "Before you begin, make sure you have all the necessary libraries installed:\n",
        "\n",
        "```bash\n",
        "pip install transformers datasets evaluate\n",
        "```\n",
        "\n",
        "We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m0moU-wINoqz"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5db22af9b4c74f1abf62226d1c4de3f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n",
        "\n",
        "#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"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUpFDnxpNoqz"
      },
      "source": [
        "## Load IMDb dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7QWQHleNoq0"
      },
      "source": [
        "Start by loading the IMDb dataset from the ü§ó Datasets library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yi6Jrqw4Noq0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb = load_dataset(\"imdb\")\n",
        "sst2 = load_dataset(\"SetFit/sst2\")\n",
        "sst5 = load_dataset(\"SetFit/sst5\")\n",
        "twitterfin = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n",
        "agnews = load_dataset(\"ag_news\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'no movement , no yuks , not much of anything .',\n",
              " 'label': 0,\n",
              " 'label_text': 'negative'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sst2['test'][0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGSkJSQ5Noq1"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcVgwUOdNoq1"
      },
      "source": [
        "The next step is to load a DistilBERT tokenizer to preprocess the `text` field:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxsQUau7Noq1"
      },
      "source": [
        "Create a preprocessing function to tokenize `text` and truncate sequences to be no longer than DistilBERT's maximum input length:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9YTQxBulNoq1"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoTokenizer\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "\n",
        "# def preprocess_function(examples):\n",
        "#     return tokenizer(examples.get('text', examples.get('sentence', '')), truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add different paddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imdb_padding_0 3\n",
            "imdb_padding_10 3\n",
            "imdb_padding_20 3\n",
            "imdb_padding_30 3\n",
            "imdb_padding_40 3\n",
            "imdb_padding_50 3\n",
            "imdb_padding_60 3\n",
            "imdb_padding_70 3\n",
            "imdb_padding_80 3\n",
            "imdb_padding_90 3\n",
            "imdb_padding_100 3\n",
            "sst2_padding_0 3\n",
            "sst2_padding_10 3\n",
            "sst2_padding_20 3\n",
            "sst2_padding_30 3\n",
            "sst2_padding_40 3\n",
            "sst2_padding_50 3\n",
            "sst2_padding_60 3\n",
            "sst2_padding_70 3\n",
            "sst2_padding_80 3\n",
            "sst2_padding_90 3\n",
            "sst2_padding_100 3\n",
            "sst5_padding_0 3\n",
            "sst5_padding_10 3\n",
            "sst5_padding_20 3\n",
            "sst5_padding_30 3\n",
            "sst5_padding_40 3\n",
            "sst5_padding_50 3\n",
            "sst5_padding_60 3\n",
            "sst5_padding_70 3\n",
            "sst5_padding_80 3\n",
            "sst5_padding_90 3\n",
            "sst5_padding_100 3\n",
            "twitterfin_padding_0 2\n",
            "twitterfin_padding_10 2\n",
            "twitterfin_padding_20 2\n",
            "twitterfin_padding_30 2\n",
            "twitterfin_padding_40 2\n",
            "twitterfin_padding_50 2\n",
            "twitterfin_padding_60 2\n",
            "twitterfin_padding_70 2\n",
            "twitterfin_padding_80 2\n",
            "twitterfin_padding_90 2\n",
            "twitterfin_padding_100 2\n",
            "agnews_padding_0 2\n",
            "agnews_padding_10 2\n",
            "agnews_padding_20 2\n",
            "agnews_padding_30 2\n",
            "agnews_padding_40 2\n",
            "agnews_padding_50 2\n",
            "agnews_padding_60 2\n",
            "agnews_padding_70 2\n",
            "agnews_padding_80 2\n",
            "agnews_padding_90 2\n",
            "agnews_padding_100 2\n"
          ]
        }
      ],
      "source": [
        "def add_text(example, n):\n",
        "  # example is a dictionary with keys 'text' and 'label'\n",
        "  # we can modify the 'text' value and return the modified example\n",
        "  text = example.get('text', example.get('sentence', ''))\n",
        "  example['text'] = \"[PAD]\" * n + text\n",
        "  return example\n",
        "\n",
        "# for n in range(0, 101, 10):\n",
        "#     # use format method to create a variable name with n\n",
        "#     var_name = \"imdb_padding_{}\".format(n)\n",
        "#     # use exec function to execute the assignment statement\n",
        "#     exec(\"{} = imdb.map(lambda x: add_text(x, n))\".format(var_name))\n",
        "#     print(var_name, len(eval(var_name)))\n",
        "\n",
        "datasets = {'imdb': imdb, 'sst2': sst2, 'sst5': sst5, 'twitterfin': twitterfin, 'agnews': agnews}\n",
        "\n",
        "# ÂØπÊØè‰∏™Êï∞ÊçÆÈõÜËøõË°åÂ§ÑÁêÜ\n",
        "for dataset_name, dataset in datasets.items():\n",
        "    for n in range(0, 101, 10):\n",
        "        var_name = \"{}_padding_{}\".format(dataset_name, n)\n",
        "        exec(\"{} = dataset.map(lambda x: add_text(x, n))\".format(var_name))\n",
        "        print(var_name, len(eval(var_name)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': '[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]no movement , no yuks , not much of anything .',\n",
              " 'label': 0,\n",
              " 'label_text': 'negative'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sst2_padding_10[\"test\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCmFugV6Noq1"
      },
      "source": [
        "To apply the preprocessing function over the entire dataset, use ü§ó Datasets [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) function. You can speed up `map` by setting `batched=True` to process multiple elements of the dataset at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mGowaDQUNoq1"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenized_imdb_0 3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd570e97123a498291538509fdf6a78e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenized_imdb_10 3\n",
            "tokenized_imdb_20 3\n",
            "tokenized_imdb_30 3\n",
            "tokenized_imdb_40 3\n",
            "tokenized_imdb_50 3\n",
            "tokenized_imdb_60 3\n",
            "tokenized_imdb_70 3\n",
            "tokenized_imdb_80 3\n",
            "tokenized_imdb_90 3\n",
            "tokenized_imdb_100 3\n",
            "tokenized_imdb_100 100\n",
            "tokenized_sst2_0 3\n",
            "tokenized_sst2_10 3\n",
            "tokenized_sst2_20 3\n",
            "tokenized_sst2_30 3\n",
            "tokenized_sst2_40 3\n",
            "tokenized_sst2_50 3\n",
            "tokenized_sst2_60 3\n",
            "tokenized_sst2_70 3\n",
            "tokenized_sst2_80 3\n",
            "tokenized_sst2_90 3\n",
            "tokenized_sst2_100 3\n",
            "tokenized_sst2_100 100\n",
            "tokenized_sst5_0 3\n",
            "tokenized_sst5_10 3\n",
            "tokenized_sst5_20 3\n",
            "tokenized_sst5_30 3\n",
            "tokenized_sst5_40 3\n",
            "tokenized_sst5_50 3\n",
            "tokenized_sst5_60 3\n",
            "tokenized_sst5_70 3\n",
            "tokenized_sst5_80 3\n",
            "tokenized_sst5_90 3\n",
            "tokenized_sst5_100 3\n",
            "tokenized_sst5_100 100\n",
            "tokenized_twitterfin_0 2\n",
            "tokenized_twitterfin_10 2\n",
            "tokenized_twitterfin_20 2\n",
            "tokenized_twitterfin_30 2\n",
            "tokenized_twitterfin_40 2\n",
            "tokenized_twitterfin_50 2\n",
            "tokenized_twitterfin_60 2\n",
            "tokenized_twitterfin_70 2\n",
            "tokenized_twitterfin_80 2\n",
            "tokenized_twitterfin_90 2\n",
            "tokenized_twitterfin_100 2\n",
            "tokenized_twitterfin_100 100\n",
            "tokenized_agnews_0 2\n",
            "tokenized_agnews_10 2\n",
            "tokenized_agnews_20 2\n",
            "tokenized_agnews_30 2\n",
            "tokenized_agnews_40 2\n",
            "tokenized_agnews_50 2\n",
            "tokenized_agnews_60 2\n",
            "tokenized_agnews_70 2\n",
            "tokenized_agnews_80 2\n",
            "tokenized_agnews_90 2\n",
            "tokenized_agnews_100 2\n",
            "tokenized_agnews_100 100\n",
            "tokenization done\n"
          ]
        }
      ],
      "source": [
        "n_range = range(0, 101, 10)\n",
        "\n",
        "\n",
        "# ÂØπÊØè‰∏™Êï∞ÊçÆÈõÜËøõË°åÂ§ÑÁêÜ\n",
        "for dataset_name, dataset in datasets.items():\n",
        "    for n in n_range:\n",
        "        filename = f\"{dataset_name}_padding_{n}\"\n",
        "        file = eval(filename)\n",
        "        tokenized_filename = f\"tokenized_{dataset_name}_{n}\"\n",
        "        exec(f\"{tokenized_filename} = file.map(preprocess_function, batched=True)\")\n",
        "        tokenized_file = eval(tokenized_filename)\n",
        "        print(tokenized_filename, len(tokenized_file))\n",
        "    print(tokenized_filename, n)\n",
        "print(\"tokenization done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': \"[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
              " 'label': 2,\n",
              " 'input_ids': [101,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  10069,\n",
              "  2005,\n",
              "  1056,\n",
              "  1050,\n",
              "  11550,\n",
              "  2044,\n",
              "  7566,\n",
              "  9209,\n",
              "  5052,\n",
              "  3667,\n",
              "  2012,\n",
              "  6769,\n",
              "  2047,\n",
              "  8095,\n",
              "  2360,\n",
              "  2027,\n",
              "  2024,\n",
              "  1005,\n",
              "  9364,\n",
              "  1005,\n",
              "  2044,\n",
              "  7566,\n",
              "  2007,\n",
              "  16654,\n",
              "  6687,\n",
              "  3813,\n",
              "  2976,\n",
              "  9587,\n",
              "  24848,\n",
              "  1012,\n",
              "  102],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_agnews_100[\"test\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozXuQzlzNoq1"
      },
      "source": [
        "Now create a batch of examples using [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xniYoauiNoq1"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZZnNUqeNoq2"
      },
      "source": [
        "Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the ü§ó [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) metric (see the ü§ó Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GB22F2o6Noq2"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abI1JqnoNoq2"
      },
      "source": [
        "Then create a function that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ICjpsPhINoq2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxGSNjrzNoq2"
      },
      "source": [
        "Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjV0JCVRNoq2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0iHhWS9Noq2"
      },
      "source": [
        "Before you start training your model, create a map of the expected ids to their labels with `id2label` and `label2id`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# imdb\n",
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "# define the range of n\n",
        "\n",
        "for n in n_range:\n",
        "    # use format method to create a variable name with n\n",
        "    variable = f\"tokenized_imdb_{n}\"\n",
        "    output_dir = f\"left_padding{n}model\"\n",
        "    logging_dir=f\"left_padding{n}model_logs\"\n",
        "\n",
        "    # use exec function to execute the assignment statement\n",
        "    var = eval(variable)\n",
        "    training_args = TrainingArguments(\n",
        "        \n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=10,\n",
        "        weight_decay=0.01,\n",
        "        \n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "\n",
        "        push_to_hub=True,\n",
        "        output_dir=output_dir,\n",
        "        seed=42,\n",
        "        data_seed=123,\n",
        "    )\n",
        "    \n",
        "    # define the trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=var[\"train\"],\n",
        "        eval_dataset=var[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train(resume_from_checkpoint=True)\n",
        "    trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f95e2b7b6f041cbab810d50b8dd15cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b292421570174540b1b36d50516c1f53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6953288316726685, 'eval_accuracy': 0.49917627677100496, 'eval_runtime': 2.4475, 'eval_samples_per_second': 744.038, 'eval_steps_per_second': 46.579, 'epoch': 0.01}\n",
            "{'train_runtime': 9.0773, 'train_samples_per_second': 7.623, 'train_steps_per_second': 0.551, 'train_loss': 0.6956593990325928, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08f1ffa34ae844819e8610d02baabdf3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c2fcd3a792545bf9ff2b86bf109994e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6975795030593872, 'eval_accuracy': 0.4975288303130148, 'eval_runtime': 2.9172, 'eval_samples_per_second': 624.219, 'eval_steps_per_second': 39.078, 'epoch': 0.01}\n",
            "{'train_runtime': 6.8435, 'train_samples_per_second': 10.112, 'train_steps_per_second': 0.731, 'train_loss': 0.6858995914459228, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcb5d9acabfd4b4495f5dca327b1a149",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "848ffbf20f454e3bb78dc7da0263a787",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6994195580482483, 'eval_accuracy': 0.48105436573311366, 'eval_runtime': 3.3185, 'eval_samples_per_second': 548.744, 'eval_steps_per_second': 34.353, 'epoch': 0.01}\n",
            "{'train_runtime': 7.237, 'train_samples_per_second': 9.562, 'train_steps_per_second': 0.691, 'train_loss': 0.6899939060211182, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dd5d148465f44a2ab4f8eaba04b1427",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4baab0207c9479e82391e93d3ceeec3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7210732698440552, 'eval_accuracy': 0.49697968149368477, 'eval_runtime': 3.7304, 'eval_samples_per_second': 488.151, 'eval_steps_per_second': 30.56, 'epoch': 0.01}\n",
            "{'train_runtime': 8.7625, 'train_samples_per_second': 7.897, 'train_steps_per_second': 0.571, 'train_loss': 0.68722562789917, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77cc0dd32a2a463aaf7b62853a085a8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54ccd28b0d764809a76fd23ce40d352a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7228018641471863, 'eval_accuracy': 0.4673256452498627, 'eval_runtime': 4.2282, 'eval_samples_per_second': 430.681, 'eval_steps_per_second': 26.962, 'epoch': 0.01}\n",
            "{'train_runtime': 8.2898, 'train_samples_per_second': 8.348, 'train_steps_per_second': 0.603, 'train_loss': 0.6524814128875732, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6ca574fd00c4b5c90a520e5d6bf665a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fac407f686564769958cc6d4b3b88453",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7667254209518433, 'eval_accuracy': 0.5057660626029654, 'eval_runtime': 4.6891, 'eval_samples_per_second': 388.347, 'eval_steps_per_second': 24.312, 'epoch': 0.01}\n",
            "{'train_runtime': 9.4305, 'train_samples_per_second': 7.338, 'train_steps_per_second': 0.53, 'train_loss': 0.684022855758667, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21934c6695eb4dcf9df266748da7db9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "841764d06acc43d4844a17f07fb8b123",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7972058057785034, 'eval_accuracy': 0.4733662822624931, 'eval_runtime': 5.3893, 'eval_samples_per_second': 337.889, 'eval_steps_per_second': 21.153, 'epoch': 0.01}\n",
            "{'train_runtime': 10.1701, 'train_samples_per_second': 6.804, 'train_steps_per_second': 0.492, 'train_loss': 0.6042176246643066, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "358bcb88d0a94b77804ceeecb86955c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e6d5f26e50847a4bf4245ae3f81f329",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8633940815925598, 'eval_accuracy': 0.49368478857770454, 'eval_runtime': 5.853, 'eval_samples_per_second': 311.122, 'eval_steps_per_second': 19.477, 'epoch': 0.01}\n",
            "{'train_runtime': 9.4219, 'train_samples_per_second': 7.345, 'train_steps_per_second': 0.531, 'train_loss': 0.6667703628540039, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6989248000a44e79a6f0960f55ca5175",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45852ab859484ba5bd4c93ad481a6f45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9500973224639893, 'eval_accuracy': 0.4958813838550247, 'eval_runtime': 6.2933, 'eval_samples_per_second': 289.356, 'eval_steps_per_second': 18.115, 'epoch': 0.01}\n",
            "{'train_runtime': 11.707, 'train_samples_per_second': 5.911, 'train_steps_per_second': 0.427, 'train_loss': 0.6533186912536622, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1ec8e6849cf42cc8a23639c8ec7b2cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de7cb4b01e0f4d43b88f8050b1da01ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.0395991802215576, 'eval_accuracy': 0.4876441515650741, 'eval_runtime': 6.8627, 'eval_samples_per_second': 265.347, 'eval_steps_per_second': 16.611, 'epoch': 0.01}\n",
            "{'train_runtime': 11.4785, 'train_samples_per_second': 6.029, 'train_steps_per_second': 0.436, 'train_loss': 0.6353700160980225, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2524479dc97420a89f6a43415e8540b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b604bb52e2434d34a757f332ee77a8f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.1704916954040527, 'eval_accuracy': 0.46787479406919275, 'eval_runtime': 7.3234, 'eval_samples_per_second': 248.656, 'eval_steps_per_second': 15.567, 'epoch': 0.01}\n",
            "{'train_runtime': 11.4769, 'train_samples_per_second': 6.029, 'train_steps_per_second': 0.436, 'train_loss': 0.6735086441040039, 'epoch': 0.01}\n"
          ]
        }
      ],
      "source": [
        "# sst2: https://huggingface.co/datasets/SetFit/sst2\n",
        "\n",
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "# define the range of n\n",
        "\n",
        "for n in n_range:\n",
        "    # use format method to create a variable name with n\n",
        "    variable = f\"tokenized_sst2_{n}\"\n",
        "    output_dir = f\"sst2_padding{n}model\"\n",
        "    logging_dir=f\"sst2_padding{n}model_logs\"\n",
        "\n",
        "    # use exec function to execute the assignment statement\n",
        "    var = eval(variable)\n",
        "    training_args = TrainingArguments(\n",
        "        \n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=0.01,\n",
        "        weight_decay=0.01,\n",
        "        \n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "\n",
        "        push_to_hub=True,\n",
        "        output_dir=output_dir,\n",
        "        seed=42,\n",
        "        data_seed=123,\n",
        "    )\n",
        "    \n",
        "    # define the trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=var[\"train\"],\n",
        "        eval_dataset=var[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    #trainer.train(resume_from_checkpoint=True)\n",
        "    trainer.train()\n",
        "    trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d60b8542603c46379481e9f005304715",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61b317e0a3ab4cba9df99bceffe8f755",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.6022824048995972, 'eval_accuracy': 0.23846153846153847, 'eval_runtime': 3.018, 'eval_samples_per_second': 732.282, 'eval_steps_per_second': 46.058, 'epoch': 0.01}\n",
            "{'train_runtime': 7.8053, 'train_samples_per_second': 10.946, 'train_steps_per_second': 0.769, 'train_loss': 1.6150665283203125, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30f374f7bd87455e8aa4f8a1057c871f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fed6770685140d08cd5df414ddffa9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.5842775106430054, 'eval_accuracy': 0.28009049773755657, 'eval_runtime': 3.6487, 'eval_samples_per_second': 605.695, 'eval_steps_per_second': 38.096, 'epoch': 0.01}\n",
            "{'train_runtime': 8.2315, 'train_samples_per_second': 10.38, 'train_steps_per_second': 0.729, 'train_loss': 1.5888927777608235, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6f582e70dd74e70b324091fdb848ccb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d91c19e8295c4e1d968616c443435d49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.5739518404006958, 'eval_accuracy': 0.28778280542986423, 'eval_runtime': 4.1866, 'eval_samples_per_second': 527.878, 'eval_steps_per_second': 33.201, 'epoch': 0.01}\n",
            "{'train_runtime': 9.4989, 'train_samples_per_second': 8.995, 'train_steps_per_second': 0.632, 'train_loss': 1.5661211013793945, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1b8fdc240d34bf483ed92a9ce6c16af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85d609d329cf4cfd8df2e9d09e4c8d90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.565750241279602, 'eval_accuracy': 0.2895927601809955, 'eval_runtime': 4.8345, 'eval_samples_per_second': 457.128, 'eval_steps_per_second': 28.751, 'epoch': 0.01}\n",
            "{'train_runtime': 8.94, 'train_samples_per_second': 9.557, 'train_steps_per_second': 0.671, 'train_loss': 1.5298943519592285, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "907259e6bb3446a1b84d22fbb93f4a3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f12d589fafdb4b689108532bc233f760",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.5655057430267334, 'eval_accuracy': 0.28778280542986423, 'eval_runtime': 5.4461, 'eval_samples_per_second': 405.793, 'eval_steps_per_second': 25.523, 'epoch': 0.01}\n",
            "{'train_runtime': 10.11, 'train_samples_per_second': 8.451, 'train_steps_per_second': 0.593, 'train_loss': 1.5098872184753418, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c5519ee13064d18b88631ff34df8d05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85d53b85edb1493c8eea1d89b7da5491",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.5651577711105347, 'eval_accuracy': 0.2900452488687783, 'eval_runtime': 6.2195, 'eval_samples_per_second': 355.335, 'eval_steps_per_second': 22.349, 'epoch': 0.01}\n",
            "{'train_runtime': 11.9717, 'train_samples_per_second': 7.137, 'train_steps_per_second': 0.501, 'train_loss': 1.5065964063008626, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba86588ad1bd4847910631378de48ac6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1ec5be5498c48b79bbb92b95c2a5c07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.5560145378112793, 'eval_accuracy': 0.302262443438914, 'eval_runtime': 6.4332, 'eval_samples_per_second': 343.531, 'eval_steps_per_second': 21.607, 'epoch': 0.01}\n",
            "{'train_runtime': 11.6322, 'train_samples_per_second': 7.345, 'train_steps_per_second': 0.516, 'train_loss': 1.4822359085083008, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce80ffe4f4b54930b81c8eaed6bde21d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f3712387906449d8887838b596acc6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.5509940385818481, 'eval_accuracy': 0.3389140271493213, 'eval_runtime': 7.2152, 'eval_samples_per_second': 306.3, 'eval_steps_per_second': 19.265, 'epoch': 0.01}\n",
            "{'train_runtime': 11.4715, 'train_samples_per_second': 7.448, 'train_steps_per_second': 0.523, 'train_loss': 1.445456822713216, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0770e3d35adc452db30127f63493e348",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7277a4e8e964577a93cb0b185de7f3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.5507333278656006, 'eval_accuracy': 0.33710407239819007, 'eval_runtime': 7.5398, 'eval_samples_per_second': 293.112, 'eval_steps_per_second': 18.436, 'epoch': 0.01}\n",
            "{'train_runtime': 13.7765, 'train_samples_per_second': 6.202, 'train_steps_per_second': 0.436, 'train_loss': 1.4012468655904133, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92dc882f658f4729911ab4744b7aedd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b946e90fb0b64e5fa453ccf834108da2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.5402005910873413, 'eval_accuracy': 0.3393665158371041, 'eval_runtime': 8.5474, 'eval_samples_per_second': 258.559, 'eval_steps_per_second': 16.262, 'epoch': 0.01}\n",
            "{'train_runtime': 15.2755, 'train_samples_per_second': 5.593, 'train_steps_per_second': 0.393, 'train_loss': 1.3631470998128254, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b0aa63d07d74f3f9e83623701422505",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9dfed9aa47d448d9b995564e0a23c01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/139 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.5398588180541992, 'eval_accuracy': 0.3375565610859729, 'eval_runtime': 9.7149, 'eval_samples_per_second': 227.485, 'eval_steps_per_second': 14.308, 'epoch': 0.01}\n",
            "{'train_runtime': 15.623, 'train_samples_per_second': 5.469, 'train_steps_per_second': 0.384, 'train_loss': 1.3308571179707844, 'epoch': 0.01}\n"
          ]
        }
      ],
      "source": [
        "# sst5: https://huggingface.co/datasets/SetFit/sst5\n",
        "\n",
        "id2label = {4: \"very positive\", 3: \"positive\", 2: \"neutral\", 1: \"negative\", 0: \"very negative\"}\n",
        "label2id = {\"very positive\": 4, \"positive\": 3, \"neutral\": 2, \"negative\": 1, \"very negative\": 0}\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=5, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "# define the range of n\n",
        "\n",
        "for n in n_range:\n",
        "    # use format method to create a variable name with n\n",
        "    variable = f\"tokenized_sst5_{n}\"\n",
        "    output_dir = f\"sst5_padding{n}model\"\n",
        "    logging_dir=f\"sst5_padding{n}model_logs\"\n",
        "\n",
        "    # use exec function to execute the assignment statement\n",
        "    var = eval(variable)\n",
        "    training_args = TrainingArguments(\n",
        "        \n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=0.01,\n",
        "        weight_decay=0.01,\n",
        "        \n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "\n",
        "        push_to_hub=True,\n",
        "        output_dir=output_dir,\n",
        "        seed=42,\n",
        "        data_seed=123,\n",
        "    )\n",
        "    \n",
        "    # define the trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=var[\"train\"],\n",
        "        eval_dataset=var[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "    \n",
        "    #trainer.train(resume_from_checkpoint=True)\n",
        "    trainer.train()\n",
        "\n",
        "    trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "530a63063d3f4b3a9f2617f9fbb97792",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5663, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e755fb8e1d54bbeb8ef54aa877df8ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4012547731399536, 'eval_accuracy': 0.8513400335008375, 'eval_runtime': 3.7193, 'eval_samples_per_second': 642.061, 'eval_steps_per_second': 40.33, 'epoch': 1.0}\n",
            "{'train_runtime': 60.4189, 'train_samples_per_second': 157.947, 'train_steps_per_second': 9.881, 'train_loss': 0.5491338439123514, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33cf1317f2c848b583f718909acbe440",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3845, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a54debd739044b1809ae022d0c6acca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.34795135259628296, 'eval_accuracy': 0.8743718592964824, 'eval_runtime': 4.2634, 'eval_samples_per_second': 560.114, 'eval_steps_per_second': 35.183, 'epoch': 1.0}\n",
            "{'train_runtime': 67.3437, 'train_samples_per_second': 141.706, 'train_steps_per_second': 8.865, 'train_loss': 0.38838475034065184, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94a9bebeb3f6402ebdf9dbd8c0f60718",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2897, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b7485df96854ad391e4f5a36981d9c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.35290542244911194, 'eval_accuracy': 0.86892797319933, 'eval_runtime': 4.9902, 'eval_samples_per_second': 478.534, 'eval_steps_per_second': 30.059, 'epoch': 1.0}\n",
            "{'train_runtime': 70.6744, 'train_samples_per_second': 135.028, 'train_steps_per_second': 8.447, 'train_loss': 0.3037401004452602, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5678fc8b59549378520b222209fb62c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2299, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1264a7e19c14f3aaa20f27e9f884a2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.40427643060684204, 'eval_accuracy': 0.8639028475711893, 'eval_runtime': 5.6457, 'eval_samples_per_second': 422.979, 'eval_steps_per_second': 26.569, 'epoch': 1.0}\n",
            "{'train_runtime': 79.4716, 'train_samples_per_second': 120.081, 'train_steps_per_second': 7.512, 'train_loss': 0.260514609178706, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1adfa5755d44151beadc9fc6ed53c13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1885, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dec38841ec09489999b49cac661caed8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4547550678253174, 'eval_accuracy': 0.8722780569514238, 'eval_runtime': 6.2581, 'eval_samples_per_second': 381.586, 'eval_steps_per_second': 23.969, 'epoch': 1.0}\n",
            "{'train_runtime': 86.4189, 'train_samples_per_second': 110.427, 'train_steps_per_second': 6.908, 'train_loss': 0.23381399669040187, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be5050bcef50483ba7166dd53cfa2c1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1626, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9b2b7c391c2415eb88e1eb1ebef41c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5107681751251221, 'eval_accuracy': 0.8739530988274706, 'eval_runtime': 7.3353, 'eval_samples_per_second': 325.551, 'eval_steps_per_second': 20.449, 'epoch': 1.0}\n",
            "{'train_runtime': 101.0037, 'train_samples_per_second': 94.482, 'train_steps_per_second': 5.911, 'train_loss': 0.21660090051903397, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2542d733047d462c8bf5ced5109992d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1487, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7751678a35f24a059271a07ee9da9133",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.583983838558197, 'eval_accuracy': 0.8739530988274706, 'eval_runtime': 8.3663, 'eval_samples_per_second': 285.432, 'eval_steps_per_second': 17.929, 'epoch': 1.0}\n",
            "{'train_runtime': 112.0678, 'train_samples_per_second': 85.154, 'train_steps_per_second': 5.327, 'train_loss': 0.2060726747241252, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cdc17744c5e4bd4a4f271836b2da2ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1322, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d98b340eb75f400aa8b73c2441bddc5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.631811797618866, 'eval_accuracy': 0.8760469011725294, 'eval_runtime': 9.253, 'eval_samples_per_second': 258.079, 'eval_steps_per_second': 16.211, 'epoch': 1.0}\n",
            "{'train_runtime': 120.3685, 'train_samples_per_second': 79.282, 'train_steps_per_second': 4.96, 'train_loss': 0.1944433943909816, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fceaa1a5234481a930d6580d7801a09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1113, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55239c49ff834dc8b63bdbe7cb125c26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6689165830612183, 'eval_accuracy': 0.864321608040201, 'eval_runtime': 10.3076, 'eval_samples_per_second': 231.673, 'eval_steps_per_second': 14.552, 'epoch': 1.0}\n",
            "{'train_runtime': 132.1456, 'train_samples_per_second': 72.216, 'train_steps_per_second': 4.518, 'train_loss': 0.17782326958686662, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f4c91e378fd4e75a50ebaf0836b115d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1083, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50b83ed9d7ea414691697d3be6ea557f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7153224349021912, 'eval_accuracy': 0.8706030150753769, 'eval_runtime': 10.8473, 'eval_samples_per_second': 220.146, 'eval_steps_per_second': 13.828, 'epoch': 1.0}\n",
            "{'train_runtime': 138.3942, 'train_samples_per_second': 68.955, 'train_steps_per_second': 4.314, 'train_loss': 0.18571021049665645, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8a38dc3bba34d9a9c039dfdee5030c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0944, 'learning_rate': 3.2495812395309884e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf112cbb9877455d8b6feb6972420b6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7331303954124451, 'eval_accuracy': 0.8697654941373534, 'eval_runtime': 10.2221, 'eval_samples_per_second': 233.611, 'eval_steps_per_second': 14.674, 'epoch': 1.0}\n",
            "{'train_runtime': 138.2947, 'train_samples_per_second': 69.005, 'train_steps_per_second': 4.317, 'train_loss': 0.16383927950707314, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "#twitterfin: https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment\n",
        "\n",
        "id2label = {0: \"Bearish\", 1: \"Bullish\", 2: \"Neutral\"}\n",
        "label2id = {\"Bearish\": 0, \"Bullish\": 1, \"Neutral\": 2}\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "# define the range of n\n",
        "for n in n_range:\n",
        "    # use format method to create a variable name with n\n",
        "    variable = f\"tokenized_twitterfin_{n}\"\n",
        "    output_dir = f\"twitterfin_padding{n}model\"\n",
        "    logging_dir=f\"twitterfin_padding{n}model_logs\"\n",
        "\n",
        "    # use exec function to execute the assignment statement\n",
        "    var = eval(variable)\n",
        "    training_args = TrainingArguments(\n",
        "        \n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=0.01,\n",
        "        weight_decay=0.01,\n",
        "        \n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "\n",
        "        push_to_hub=True,\n",
        "        output_dir=output_dir,\n",
        "        seed=42,\n",
        "        data_seed=123,\n",
        "    )\n",
        "    \n",
        "    # define the trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=var[\"train\"],\n",
        "        eval_dataset=var[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "105276f816b346b8ab7dfacc7af8907e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9aaaaef94a4c4f41b91d70cb6de343cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7518361806869507, 'eval_accuracy': 0.8542105263157894, 'eval_runtime': 20.1254, 'eval_samples_per_second': 377.632, 'eval_steps_per_second': 23.602, 'epoch': 0.01}\n",
            "{'train_runtime': 39.5286, 'train_samples_per_second': 30.358, 'train_steps_per_second': 1.897, 'train_loss': 1.0339847819010417, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c5d8155287e41fe84e4d3d74201e65a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ef667e3685b4befa19f132282a30b14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4200113117694855, 'eval_accuracy': 0.8769736842105263, 'eval_runtime': 21.9953, 'eval_samples_per_second': 345.528, 'eval_steps_per_second': 21.595, 'epoch': 0.01}\n",
            "{'train_runtime': 45.5323, 'train_samples_per_second': 26.355, 'train_steps_per_second': 1.647, 'train_loss': 0.5153947448730469, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d71ff7e5d6d47cdbc4216aba8cbf0c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b4a260eb1264b7a946bd817a82a679b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.35912051796913147, 'eval_accuracy': 0.8864473684210527, 'eval_runtime': 24.1721, 'eval_samples_per_second': 314.412, 'eval_steps_per_second': 19.651, 'epoch': 0.01}\n",
            "{'train_runtime': 47.784, 'train_samples_per_second': 25.113, 'train_steps_per_second': 1.57, 'train_loss': 0.36050994873046877, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e80643e30c4e4f7aa3dc842fa8bc4294",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e3c96dd0fbb4aa4a704657da61a4b56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3472963571548462, 'eval_accuracy': 0.89, 'eval_runtime': 26.508, 'eval_samples_per_second': 286.706, 'eval_steps_per_second': 17.919, 'epoch': 0.01}\n",
            "{'train_runtime': 52.6805, 'train_samples_per_second': 22.779, 'train_steps_per_second': 1.424, 'train_loss': 0.2943467458089193, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3b3a98a3fb545a1b8db260829cbe780",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44bf62a6b371455b8a51c0b37cbdd14a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3629646897315979, 'eval_accuracy': 0.8922368421052631, 'eval_runtime': 29.5337, 'eval_samples_per_second': 257.333, 'eval_steps_per_second': 16.083, 'epoch': 0.01}\n",
            "{'train_runtime': 56.0654, 'train_samples_per_second': 21.404, 'train_steps_per_second': 1.338, 'train_loss': 0.24894274393717447, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b5d57e0c1654ef58472cfa0bd25201d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3943999cf9f4e479b6f905ba5b281a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3956390917301178, 'eval_accuracy': 0.886578947368421, 'eval_runtime': 31.1604, 'eval_samples_per_second': 243.899, 'eval_steps_per_second': 15.244, 'epoch': 0.01}\n",
            "{'train_runtime': 58.8163, 'train_samples_per_second': 20.403, 'train_steps_per_second': 1.275, 'train_loss': 0.20261423746744792, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e2e936522c74d77b6d186a175f52a40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45fcaae858e24536b0170c5c21cead46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.45044973492622375, 'eval_accuracy': 0.8881578947368421, 'eval_runtime': 34.3238, 'eval_samples_per_second': 221.421, 'eval_steps_per_second': 13.839, 'epoch': 0.01}\n",
            "{'train_runtime': 65.8629, 'train_samples_per_second': 18.22, 'train_steps_per_second': 1.139, 'train_loss': 0.1922247568766276, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4450d6bc390944d4b3da911356e73ab7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "119b5df058d34a17b9512b9080867445",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4824838936328888, 'eval_accuracy': 0.8867105263157895, 'eval_runtime': 36.8704, 'eval_samples_per_second': 206.128, 'eval_steps_per_second': 12.883, 'epoch': 0.01}\n",
            "{'train_runtime': 69.6692, 'train_samples_per_second': 17.224, 'train_steps_per_second': 1.077, 'train_loss': 0.17889537811279296, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e72844e8bcb74162905a7d589075f444",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "904074f284f44aa290de1bb0e9136a34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5680945515632629, 'eval_accuracy': 0.8846052631578948, 'eval_runtime': 38.4431, 'eval_samples_per_second': 197.695, 'eval_steps_per_second': 12.356, 'epoch': 0.01}\n",
            "{'train_runtime': 74.0548, 'train_samples_per_second': 16.204, 'train_steps_per_second': 1.013, 'train_loss': 0.18295463562011718, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6a01442ac6b4d3da8e78a721b68bce8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cac550033cf34c45a13a94459b3c7a91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6541604995727539, 'eval_accuracy': 0.8827631578947368, 'eval_runtime': 42.3707, 'eval_samples_per_second': 179.369, 'eval_steps_per_second': 11.211, 'epoch': 0.01}\n",
            "{'train_runtime': 85.1027, 'train_samples_per_second': 14.101, 'train_steps_per_second': 0.881, 'train_loss': 0.19648821512858072, 'epoch': 0.01}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95fa20ae01b642819b19e875c73d5ed0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52de238df41f48c1b93dac100c5e1bcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/475 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7492882609367371, 'eval_accuracy': 0.8761842105263158, 'eval_runtime': 64.3874, 'eval_samples_per_second': 118.036, 'eval_steps_per_second': 7.377, 'epoch': 0.01}\n",
            "{'train_runtime': 120.7853, 'train_samples_per_second': 9.935, 'train_steps_per_second': 0.621, 'train_loss': 0.19611497243245443, 'epoch': 0.01}\n"
          ]
        }
      ],
      "source": [
        "# agnews: https://huggingface.co/datasets/ag_news\n",
        "\n",
        "id2label = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
        "label2id = {\"World\": 0, \"Sports\": 1, \"Business\": 2, \"Sci/Tech\": 3}\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=4, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "# define the range of n\n",
        "for n in n_range:\n",
        "    # use format method to create a variable name with n\n",
        "    variable = f\"tokenized_agnews_{n}\"\n",
        "    output_dir = f\"agnews_padding{n}model\"\n",
        "    logging_dir=f\"agnews_padding{n}model_logs\"\n",
        "\n",
        "    # use exec function to execute the assignment statement\n",
        "    var = eval(variable)\n",
        "    training_args = TrainingArguments(\n",
        "        \n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=0.01,\n",
        "        weight_decay=0.01,\n",
        "        \n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "\n",
        "        push_to_hub=True,\n",
        "        output_dir=output_dir,\n",
        "        seed=42,\n",
        "        data_seed=123,\n",
        "    )\n",
        "    \n",
        "    # define the trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=var[\"train\"],\n",
        "        eval_dataset=var[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    #trainer.train(resume_from_checkpoint=True)\n",
        "    trainer.train()\n",
        "    trainer.push_to_hub()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6deZu6ETNoq2"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "If you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n",
        "\n",
        "</Tip>\n",
        "\n",
        "You're ready to start training your model now! Load DistilBERT with [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification) along with the number of expected labels, and the label mappings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sYPVBpCPNoq2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"left_padding0model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    \n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    seed=42,\n",
        "    data_seed=123)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb_0[\"train\"],\n",
        "    eval_dataset=tokenized_imdb_0[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train(resume_from_checkpoint=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc24f8766f334bacb06e07c96462f992",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3126 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 0.1256, 'train_samples_per_second': 398145.539, 'train_steps_per_second': 24892.059, 'train_loss': 0.0, 'epoch': 20.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=31260, training_loss=0.0, metrics={'train_runtime': 0.1256, 'train_samples_per_second': 398145.539, 'train_steps_per_second': 24892.059, 'train_loss': 0.0, 'epoch': 20.0})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"left_padding0model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    \n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    seed=42,\n",
        "    data_seed=123)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb_0[\"train\"],\n",
        "    eval_dataset=tokenized_imdb_0[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train(resume_from_checkpoint=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f580dc65a861409baa879d8c20419287",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60489ad0d2814c2ab9b1aef1e862d924",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "NameError",
          "evalue": "name 'json' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\wyzhw\\Documents\\GitHub\\Bert_test\\bert_padding_test.ipynb ÂçïÂÖÉÊ†º 37\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y150sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     results[n] \u001b[39m=\u001b[39m result\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y150sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mresults.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y150sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(results, f)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "results = {}\n",
        "\n",
        "for n in range(0, 11, 10):\n",
        "    result = trainer.evaluate()\n",
        "    results[n] = result\n",
        "\n",
        "\n",
        "with open(\"results.json\", \"w\") as f:\n",
        "    json.dump(results, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: {'eval_loss': 0.23403853178024292,\n",
              "  'eval_accuracy': 0.9166,\n",
              "  'eval_runtime': 357.8435,\n",
              "  'eval_samples_per_second': 69.863,\n",
              "  'eval_steps_per_second': 4.368,\n",
              "  'epoch': 2.0},\n",
              " 10: {'eval_loss': 0.23403853178024292,\n",
              "  'eval_accuracy': 0.9166,\n",
              "  'eval_runtime': 364.259,\n",
              "  'eval_samples_per_second': 68.632,\n",
              "  'eval_steps_per_second': 4.291,\n",
              "  'epoch': 2.0}}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30e5cbabac1447d59bf07571bf338019",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3126 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1914, 'learning_rate': 1.9360204734484968e-05, 'epoch': 0.06}\n",
            "{'loss': 0.1357, 'learning_rate': 1.872040946896993e-05, 'epoch': 0.13}\n",
            "{'loss': 0.1454, 'learning_rate': 1.8080614203454897e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2537, 'learning_rate': 1.744081893793986e-05, 'epoch': 0.26}\n",
            "{'loss': 0.2634, 'learning_rate': 1.6801023672424827e-05, 'epoch': 0.32}\n",
            "{'loss': 0.2562, 'learning_rate': 1.616122840690979e-05, 'epoch': 0.38}\n",
            "{'loss': 0.2484, 'learning_rate': 1.5521433141394756e-05, 'epoch': 0.45}\n",
            "{'loss': 0.2546, 'learning_rate': 1.488163787587972e-05, 'epoch': 0.51}\n",
            "{'loss': 0.2496, 'learning_rate': 1.4241842610364684e-05, 'epoch': 0.58}\n",
            "{'loss': 0.2291, 'learning_rate': 1.3602047344849649e-05, 'epoch': 0.64}\n",
            "{'loss': 0.2437, 'learning_rate': 1.2962252079334613e-05, 'epoch': 0.7}\n",
            "{'loss': 0.2125, 'learning_rate': 1.2322456813819578e-05, 'epoch': 0.77}\n",
            "{'loss': 0.2148, 'learning_rate': 1.1682661548304543e-05, 'epoch': 0.83}\n",
            "{'loss': 0.2183, 'learning_rate': 1.1042866282789508e-05, 'epoch': 0.9}\n",
            "{'loss': 0.2242, 'learning_rate': 1.0403071017274472e-05, 'epoch': 0.96}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e55e1d0d37514cdfb9bf0a11c72ab435",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.22205103933811188, 'eval_runtime': 363.4682, 'eval_samples_per_second': 68.782, 'eval_steps_per_second': 4.3, 'epoch': 1.0}\n",
            "{'loss': 0.171, 'learning_rate': 9.763275751759437e-06, 'epoch': 1.02}\n",
            "{'loss': 0.1388, 'learning_rate': 9.123480486244403e-06, 'epoch': 1.09}\n",
            "{'loss': 0.1527, 'learning_rate': 8.483685220729368e-06, 'epoch': 1.15}\n",
            "{'loss': 0.1351, 'learning_rate': 7.843889955214333e-06, 'epoch': 1.22}\n",
            "{'loss': 0.144, 'learning_rate': 7.204094689699297e-06, 'epoch': 1.28}\n",
            "{'loss': 0.1467, 'learning_rate': 6.5642994241842614e-06, 'epoch': 1.34}\n",
            "{'loss': 0.1327, 'learning_rate': 5.924504158669226e-06, 'epoch': 1.41}\n",
            "{'loss': 0.1555, 'learning_rate': 5.284708893154191e-06, 'epoch': 1.47}\n",
            "{'loss': 0.1377, 'learning_rate': 4.644913627639156e-06, 'epoch': 1.54}\n",
            "{'loss': 0.128, 'learning_rate': 4.005118362124121e-06, 'epoch': 1.6}\n",
            "{'loss': 0.1279, 'learning_rate': 3.3653230966090854e-06, 'epoch': 1.66}\n",
            "{'loss': 0.1799, 'learning_rate': 2.72552783109405e-06, 'epoch': 1.73}\n",
            "{'loss': 0.1464, 'learning_rate': 2.085732565579015e-06, 'epoch': 1.79}\n",
            "{'loss': 0.1415, 'learning_rate': 1.4459373000639796e-06, 'epoch': 1.86}\n",
            "{'loss': 0.1378, 'learning_rate': 8.061420345489445e-07, 'epoch': 1.92}\n",
            "{'loss': 0.1131, 'learning_rate': 1.6634676903390917e-07, 'epoch': 1.98}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "571c5ebf748c4e28b5316831f7a29321",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.24687997996807098, 'eval_runtime': 362.9107, 'eval_samples_per_second': 68.887, 'eval_steps_per_second': 4.307, 'epoch': 2.0}\n",
            "{'train_runtime': 2814.2898, 'train_samples_per_second': 17.766, 'train_steps_per_second': 1.111, 'train_loss': 0.18125215174674378, 'epoch': 2.0}\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\wyzhw\\Documents\\GitHub\\Bert_test\\bert_padding_test.ipynb ÂçïÂÖÉÊ†º 36\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#X46sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m# save the metrics\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#X46sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mlog_history[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#X46sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     result[\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m n\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#X46sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     result_df \u001b[39m=\u001b[39m result_df\u001b[39m.\u001b[39mappend(result, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#X46sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m csv_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmy_data.csv\u001b[39m\u001b[39m'\u001b[39m\n",
            "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "# define the range of n\n",
        "#for n in n_range:\n",
        "for n in range(0, 11, 10):\n",
        "    # use format method to create a variable name with n\n",
        "    variable = f\"tokenized_imdb_{n}\"\n",
        "    output_dir = f\"left_padding{n}model\"\n",
        "    logging_dir=f\"left_padding{n}model_logs\"\n",
        "\n",
        "    # use exec function to execute the assignment statement\n",
        "    var = eval(variable)\n",
        "    training_args = TrainingArguments(\n",
        "        \n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=2,\n",
        "        weight_decay=0.01,\n",
        "        \n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "\n",
        "        push_to_hub=True,\n",
        "        seed=42,\n",
        "        data_seed=123,\n",
        "        output_dir=output_dir,\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=100\n",
        "    )\n",
        "    \n",
        "    # define the trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=var[\"train\"],\n",
        "        eval_dataset=var[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "    trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\wyzhw\\Documents\\GitHub\\Bert_test\\bert_padding_test.ipynb ÂçïÂÖÉÊ†º 37\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y135sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mevaluate()\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\transformers\\trainer.py:3011\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3008\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   3010\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3011\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[0;32m   3012\u001b[0m     eval_dataloader,\n\u001b[0;32m   3013\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   3014\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3015\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3016\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   3017\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[0;32m   3018\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[0;32m   3019\u001b[0m )\n\u001b[0;32m   3021\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[0;32m   3022\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\transformers\\trainer.py:3190\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3188\u001b[0m observed_num_examples \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m   3189\u001b[0m \u001b[39m# Main evaluation loop\u001b[39;00m\n\u001b[1;32m-> 3190\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m   3191\u001b[0m     \u001b[39m# Update the observed num examples\u001b[39;00m\n\u001b[0;32m   3192\u001b[0m     observed_batch_size \u001b[39m=\u001b[39m find_batch_size(inputs)\n\u001b[0;32m   3193\u001b[0m     \u001b[39mif\u001b[39;00m observed_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\accelerate\\data_loader.py:460\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m         current_batch \u001b[39m=\u001b[39m send_to_device(current_batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m    461\u001b[0m     next_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(dataloader_iter)\n\u001b[0;32m    462\u001b[0m     \u001b[39mif\u001b[39;00m batch_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_batches:\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\accelerate\\utils\\operations.py:160\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39melif\u001b[39;00m skip_keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m         skip_keys \u001b[39m=\u001b[39m []\n\u001b[0;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(tensor)(\n\u001b[1;32m--> 160\u001b[0m         {\n\u001b[0;32m    161\u001b[0m             k: t \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m skip_keys \u001b[39melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[39m=\u001b[39mnon_blocking, skip_keys\u001b[39m=\u001b[39mskip_keys)\n\u001b[0;32m    162\u001b[0m             \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m tensor\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    163\u001b[0m         }\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\accelerate\\utils\\operations.py:161\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39melif\u001b[39;00m skip_keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m         skip_keys \u001b[39m=\u001b[39m []\n\u001b[0;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(tensor)(\n\u001b[0;32m    160\u001b[0m         {\n\u001b[1;32m--> 161\u001b[0m             k: t \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m skip_keys \u001b[39melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking, skip_keys\u001b[39m=\u001b[39;49mskip_keys)\n\u001b[0;32m    162\u001b[0m             \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m tensor\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    163\u001b[0m         }\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\accelerate\\utils\\operations.py:167\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mto(device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking)\n\u001b[0;32m    168\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mto(device)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cc7ae5fbed4492fa19fcf38bc351ff5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5a5ca7160e84bc1a3c6d320d2032a37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d052eb7812324a3daa0c7a1525682a25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba3b1663a346401daa7a01dff162573d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85f5df8b126e40da9226be77d73a46f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c90d785a6a3f409abeaae2ebc2e8ffe5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Realgon/left_padding100_model\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"Realgon/left_padding100_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "for obj in trainer.state.log_history:\n",
        "    print(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\wyzhw\\Documents\\GitHub\\Bert_test\\bert_padding_test.ipynb ÂçïÂÖÉÊ†º 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39;49mlog_history[\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
            "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "trainer.state.log_history['accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'train_runtime': 2814.2898,\n",
              "  'train_samples_per_second': 17.766,\n",
              "  'train_steps_per_second': 1.111,\n",
              "  'total_flos': 6564686875195392.0,\n",
              "  'train_loss': 0.18125215174674378,\n",
              "  'epoch': 2.0,\n",
              "  'step': 3126,\n",
              "  'n': 0}]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\wyzhw\\Documents\\GitHub\\Bert_test\\bert_padding_test.ipynb ÂçïÂÖÉÊ†º 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m n\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y125sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result_df \u001b[39m=\u001b[39m result_df\u001b[39m.\u001b[39mappend(result, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "result['n'] = n\n",
        "result_df = result_df.append(result, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"left_padding50_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    seed=42,\n",
        "    data_seed=123\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb_50[\"train\"],\n",
        "    eval_dataset=tokenized_imdb_50[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34e5c891d2074e388487a232838686c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3126 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3348, 'learning_rate': 1.6801023672424827e-05, 'epoch': 0.32}\n",
            "{'loss': 0.2586, 'learning_rate': 1.3602047344849649e-05, 'epoch': 0.64}\n",
            "{'loss': 0.2306, 'learning_rate': 1.0403071017274472e-05, 'epoch': 0.96}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "972262025a1d48faaf28f4dd1f8cfaeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.26562219858169556, 'eval_accuracy': 0.90268, 'eval_runtime': 377.3093, 'eval_samples_per_second': 66.259, 'eval_steps_per_second': 4.142, 'epoch': 1.0}\n",
            "{'loss': 0.1622, 'learning_rate': 7.204094689699297e-06, 'epoch': 1.28}\n",
            "{'loss': 0.1487, 'learning_rate': 4.005118362124121e-06, 'epoch': 1.6}\n",
            "{'loss': 0.1599, 'learning_rate': 8.061420345489445e-07, 'epoch': 1.92}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d75619eff2fc45cd874a4ea2be852e3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.235260471701622, 'eval_accuracy': 0.92952, 'eval_runtime': 376.2296, 'eval_samples_per_second': 66.449, 'eval_steps_per_second': 4.154, 'epoch': 2.0}\n",
            "{'train_runtime': 2855.1642, 'train_samples_per_second': 17.512, 'train_steps_per_second': 1.095, 'train_loss': 0.2124700436436512, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3126, training_loss=0.2124700436436512, metrics={'train_runtime': 2855.1642, 'train_samples_per_second': 17.512, 'train_steps_per_second': 1.095, 'train_loss': 0.2124700436436512, 'epoch': 2.0})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"left_padding50_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    seed=42,\n",
        "    data_seed=123\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb_50[\"train\"],\n",
        "    eval_dataset=tokenized_imdb_50[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/Realgon/left_padding50_model/tree/main/'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "679b7df4b7014bada4936185bc5d5a62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3126 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1975, 'learning_rate': 1.6801023672424827e-05, 'epoch': 0.32}\n",
            "{'loss': 0.1874, 'learning_rate': 1.3602047344849649e-05, 'epoch': 0.64}\n",
            "{'loss': 0.1809, 'learning_rate': 1.0403071017274472e-05, 'epoch': 0.96}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccf43e1ce4fd47669e32c87d95e3860f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2602356970310211, 'eval_accuracy': 0.9228, 'eval_runtime': 373.1317, 'eval_samples_per_second': 67.0, 'eval_steps_per_second': 4.189, 'epoch': 1.0}\n",
            "{'loss': 0.1007, 'learning_rate': 7.204094689699297e-06, 'epoch': 1.28}\n",
            "{'loss': 0.0853, 'learning_rate': 4.005118362124121e-06, 'epoch': 1.6}\n",
            "{'loss': 0.1099, 'learning_rate': 8.061420345489445e-07, 'epoch': 1.92}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d3fd9e8ba2f4e208618b8f37b876e92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.284171462059021, 'eval_accuracy': 0.93, 'eval_runtime': 372.6626, 'eval_samples_per_second': 67.085, 'eval_steps_per_second': 4.194, 'epoch': 2.0}\n",
            "{'train_runtime': 2858.2215, 'train_samples_per_second': 17.493, 'train_steps_per_second': 1.094, 'train_loss': 0.1417671253646099, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3126, training_loss=0.1417671253646099, metrics={'train_runtime': 2858.2215, 'train_samples_per_second': 17.493, 'train_steps_per_second': 1.094, 'train_loss': 0.1417671253646099, 'epoch': 2.0})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"left_padding100_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    seed=42,\n",
        "    data_seed=123\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb_100[\"train\"],\n",
        "    eval_dataset=tokenized_imdb_100[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/Realgon/left_padding100_model/tree/main/'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_It2XfONoq2"
      },
      "source": [
        "At this point, only three steps remain:\n",
        "\n",
        "1. Define your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the accuracy and save the training checkpoint.\n",
        "2. Pass the training arguments to [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n",
        "3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TyOjmT_bNoq2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ce9f123a82c431587f40fbd6f2725fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3126 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1597, 'learning_rate': 1.6801023672424827e-05, 'epoch': 0.32}\n",
            "{'loss': 0.1511, 'learning_rate': 1.3602047344849649e-05, 'epoch': 0.64}\n",
            "{'loss': 0.1564, 'learning_rate': 1.0403071017274472e-05, 'epoch': 0.96}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ab54e82836d4d89b2ec81b4e92d1c75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2768949866294861, 'eval_accuracy': 0.92112, 'eval_runtime': 379.0743, 'eval_samples_per_second': 65.95, 'eval_steps_per_second': 4.123, 'epoch': 1.0}\n",
            "{'loss': 0.082, 'learning_rate': 7.204094689699297e-06, 'epoch': 1.28}\n",
            "{'loss': 0.0764, 'learning_rate': 4.005118362124121e-06, 'epoch': 1.6}\n",
            "{'loss': 0.0916, 'learning_rate': 8.061420345489445e-07, 'epoch': 1.92}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89ecd834a7924406a6e85f67f653c2f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3246845006942749, 'eval_accuracy': 0.92544, 'eval_runtime': 378.4581, 'eval_samples_per_second': 66.058, 'eval_steps_per_second': 4.13, 'epoch': 2.0}\n",
            "{'train_runtime': 2899.2484, 'train_samples_per_second': 17.246, 'train_steps_per_second': 1.078, 'train_loss': 0.11752973331981031, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3126, training_loss=0.11752973331981031, metrics={'train_runtime': 2899.2484, 'train_samples_per_second': 17.246, 'train_steps_per_second': 1.078, 'train_loss': 0.11752973331981031, 'epoch': 2.0})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"left_padding150_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    seed=42,\n",
        "    data_seed=123)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb_150[\"train\"],\n",
        "    eval_dataset=tokenized_imdb_150[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cef8a53f1a84305bc4dc5af5c9ea72e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4689 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0563, 'learning_rate': 5.07144380464918e-06, 'epoch': 2.24}\n",
            "{'loss': 0.0529, 'learning_rate': 2.9387929195990615e-06, 'epoch': 2.56}\n",
            "{'loss': 0.054, 'learning_rate': 8.061420345489445e-07, 'epoch': 2.88}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e9c0349d7da4c3a8f0d6ece4dfe933c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1563 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.38004031777381897, 'eval_accuracy': 0.92476, 'eval_runtime': 384.1011, 'eval_samples_per_second': 65.087, 'eval_steps_per_second': 4.069, 'epoch': 3.0}\n",
            "{'train_runtime': 1434.0528, 'train_samples_per_second': 52.299, 'train_steps_per_second': 3.27, 'train_loss': 0.01731584208889744, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4689, training_loss=0.01731584208889744, metrics={'train_runtime': 1434.0528, 'train_samples_per_second': 52.299, 'train_steps_per_second': 3.27, 'train_loss': 0.01731584208889744, 'epoch': 3.0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"left_padding150_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    seed=42,\n",
        "    data_seed=123)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb_150[\"train\"],\n",
        "    eval_dataset=tokenized_imdb_150[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train(resume_from_checkpoint=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Êó†Ê≥ïÂëàÁé∞‚Äúapplication/vnd.jupyter.widget-view+json‚ÄùÁöÑÂÜÖÂÆπ\n",
        "{\"model_id\":\"057a11bb382d417db9ab4c042ad62e75\",\"version_major\":2,\"version_minor\":0}\n",
        "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
        "{'loss': 0.3392, 'learning_rate': 1.6801023672424827e-05, 'epoch': 0.32}\n",
        "{'loss': 0.2638, 'learning_rate': 1.3602047344849649e-05, 'epoch': 0.64}\n",
        "{'loss': 0.2446, 'learning_rate': 1.0403071017274472e-05, 'epoch': 0.96}\n",
        "Êó†Ê≥ïÂëàÁé∞‚Äúapplication/vnd.jupyter.widget-view+json‚ÄùÁöÑÂÜÖÂÆπ\n",
        "{\"model_id\":\"ea2324d6b1874a199e5f632294202495\",\"version_major\":2,\"version_minor\":0}\n",
        "{'eval_loss': 0.3612774908542633, 'eval_accuracy': 0.86776, 'eval_runtime': 1436.2269, 'eval_samples_per_second': 17.407, 'eval_steps_per_second': 1.088, 'epoch': 1.0}\n",
        "{'loss': 0.1764, 'learning_rate': 7.204094689699297e-06, 'epoch': 1.28}\n",
        "{'loss': 0.1591, 'learning_rate': 4.005118362124121e-06, 'epoch': 1.6}\n",
        "{'loss': 0.1746, 'learning_rate': 8.061420345489445e-07, 'epoch': 1.92}\n",
        "Êó†Ê≥ïÂëàÁé∞‚Äúapplication/vnd.jupyter.widget-view+json‚ÄùÁöÑÂÜÖÂÆπ\n",
        "{\"model_id\":\"e11f558dc7c64eacb2d28408bf424940\",\"version_major\":2,\"version_minor\":0}\n",
        "{'eval_loss': 0.24108850955963135, 'eval_accuracy': 0.92488, 'eval_runtime': 746.9998, 'eval_samples_per_second': 33.467, 'eval_steps_per_second': 2.092, 'epoch': 2.0}\n",
        "{'train_runtime': 6886.1501, 'train_samples_per_second': 7.261, 'train_steps_per_second': 0.454, 'train_loss': 0.22320297629270353, 'epoch': 2.0}\n",
        "TrainOutput(global_step=3126, training_loss=0.22320297629270353, metrics={'train_runtime': 6886.1501, 'train_samples_per_second': 7.261, 'train_steps_per_second': 0.454, 'train_loss': 0.22320297629270353, 'epoch': 2.0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/Realgon/left_padding150_model/tree/main/'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbe734f03f6043e3a06dd165aaa2ca73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wyzhw\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "892a1e68f8774e9587732d4997d30b27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64e57c8f21a9459a812277473b31425f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5fb59a971194b7eb9659e4d6503267a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d46d4d9cffc346c2a2dbba81f6e457c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25a59f6f897c4b2e8a5e269746dc91d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "from evaluate import evaluator\n",
        "import evaluate\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"lvwerra/distilbert-imdb\", device=0)\n",
        "data = load_dataset(\"imdb\", split=\"test\").shuffle().select(range(1000))\n",
        "metric = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e809af40e31e47d9aec5b6ae8b917c85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "295ca602fc074770bc846268dc2b2f99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`data` is a preloaded Dataset! Ignoring `subset` and `split`.\n"
          ]
        },
        {
          "ename": "HFValidationError",
          "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'huggingface/Realgon/left_padding50_model'. Use `repo_type` argument if needed.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\wyzhw\\Documents\\GitHub\\Bert_test\\bert_padding_test.ipynb ÂçïÂÖÉÊ†º 55\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y142sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mevaluate\u001b[39;00m \u001b[39mimport\u001b[39;00m EvaluationSuite\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y142sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m suite \u001b[39m=\u001b[39m EvaluationSuite\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmathemakitten/sentiment-evaluation-suite\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y142sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m results \u001b[39m=\u001b[39m suite\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mhuggingface/Realgon/left_padding50_model\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\evaluate\\evaluation_suite\\__init__.py:123\u001b[0m, in \u001b[0;36mEvaluationSuite.run\u001b[1;34m(self, model_or_pipeline)\u001b[0m\n\u001b[0;32m    121\u001b[0m args_for_task[\u001b[39m\"\u001b[39m\u001b[39msubset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39msubset\n\u001b[0;32m    122\u001b[0m args_for_task[\u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39msplit\n\u001b[1;32m--> 123\u001b[0m results \u001b[39m=\u001b[39m task_evaluator\u001b[39m.\u001b[39mcompute(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs_for_task)\n\u001b[0;32m    125\u001b[0m results[\u001b[39m\"\u001b[39m\u001b[39mtask_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m task_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m task\u001b[39m.\u001b[39msubset \u001b[39mif\u001b[39;00m task\u001b[39m.\u001b[39msubset \u001b[39melse\u001b[39;00m task_name\n\u001b[0;32m    126\u001b[0m results[\u001b[39m\"\u001b[39m\u001b[39mdata_preprocessor\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(task\u001b[39m.\u001b[39mdata_preprocessor) \u001b[39mif\u001b[39;00m task\u001b[39m.\u001b[39mdata_preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\evaluate\\evaluator\\text_classification.py:134\u001b[0m, in \u001b[0;36mTextClassificationEvaluator.compute\u001b[1;34m(self, model_or_pipeline, data, subset, split, metric, tokenizer, feature_extractor, strategy, confidence_level, n_resamples, device, random_state, input_column, second_input_column, label_column, label_mapping)\u001b[0m\n\u001b[0;32m    130\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_data(data\u001b[39m=\u001b[39mdata, subset\u001b[39m=\u001b[39msubset, split\u001b[39m=\u001b[39msplit)\n\u001b[0;32m    131\u001b[0m metric_inputs, pipe_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_data(\n\u001b[0;32m    132\u001b[0m     data\u001b[39m=\u001b[39mdata, input_column\u001b[39m=\u001b[39minput_column, second_input_column\u001b[39m=\u001b[39msecond_input_column, label_column\u001b[39m=\u001b[39mlabel_column\n\u001b[0;32m    133\u001b[0m )\n\u001b[1;32m--> 134\u001b[0m pipe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_pipeline(\n\u001b[0;32m    135\u001b[0m     model_or_pipeline\u001b[39m=\u001b[39;49mmodel_or_pipeline,\n\u001b[0;32m    136\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[0;32m    137\u001b[0m     feature_extractor\u001b[39m=\u001b[39;49mfeature_extractor,\n\u001b[0;32m    138\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m    139\u001b[0m )\n\u001b[0;32m    140\u001b[0m metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_metric(metric)\n\u001b[0;32m    142\u001b[0m \u001b[39m# Compute predictions\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\evaluate\\evaluator\\base.py:460\u001b[0m, in \u001b[0;36mEvaluator.prepare_pipeline\u001b[1;34m(self, model_or_pipeline, tokenizer, feature_extractor, device)\u001b[0m\n\u001b[0;32m    453\u001b[0m     device \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_infer_device()\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    456\u001b[0m     \u001b[39misinstance\u001b[39m(model_or_pipeline, \u001b[39mstr\u001b[39m)\n\u001b[0;32m    457\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(model_or_pipeline, transformers\u001b[39m.\u001b[39mPreTrainedModel)\n\u001b[0;32m    458\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(model_or_pipeline, transformers\u001b[39m.\u001b[39mTFPreTrainedModel)\n\u001b[0;32m    459\u001b[0m ):\n\u001b[1;32m--> 460\u001b[0m     pipe \u001b[39m=\u001b[39m pipeline(\n\u001b[0;32m    461\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask,\n\u001b[0;32m    462\u001b[0m         model\u001b[39m=\u001b[39;49mmodel_or_pipeline,\n\u001b[0;32m    463\u001b[0m         tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[0;32m    464\u001b[0m         feature_extractor\u001b[39m=\u001b[39;49mfeature_extractor,\n\u001b[0;32m    465\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    467\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m     \u001b[39mif\u001b[39;00m model_or_pipeline \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\transformers\\pipelines\\__init__.py:747\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m     pretrained_model_name_or_path \u001b[39m=\u001b[39m model\n\u001b[0;32m    745\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig) \u001b[39mand\u001b[39;00m pretrained_model_name_or_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    746\u001b[0m     \u001b[39m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m--> 747\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[0;32m    748\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    749\u001b[0m         CONFIG_NAME,\n\u001b[0;32m    750\u001b[0m         _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    751\u001b[0m         _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    752\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    753\u001b[0m     )\n\u001b[0;32m    754\u001b[0m     hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    755\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\transformers\\utils\\hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    428\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    429\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    431\u001b[0m         path_or_repo_id,\n\u001b[0;32m    432\u001b[0m         filename,\n\u001b[0;32m    433\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    434\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m    435\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    436\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    437\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    438\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    439\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    440\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    441\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m    442\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    443\u001b[0m     )\n\u001b[0;32m    444\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mfor\u001b[39;00m arg_name, arg_value \u001b[39min\u001b[39;00m chain(\n\u001b[0;32m    106\u001b[0m     \u001b[39mzip\u001b[39m(signature\u001b[39m.\u001b[39mparameters, args),  \u001b[39m# Args values\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     kwargs\u001b[39m.\u001b[39mitems(),  \u001b[39m# Kwargs values\u001b[39;00m\n\u001b[0;32m    108\u001b[0m ):\n\u001b[0;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 110\u001b[0m         validate_repo_id(arg_value)\n\u001b[0;32m    112\u001b[0m     \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         has_token \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\wyzhw\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRepo id must be a string, not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(repo_id)\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n\u001b[0;32m    164\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    165\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must use alphanumeric chars or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m forbidden, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m cannot start or end the name, max length is 96:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n",
            "\u001b[1;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'huggingface/Realgon/left_padding50_model'. Use `repo_type` argument if needed."
          ]
        }
      ],
      "source": [
        "from evaluate import EvaluationSuite\n",
        "suite = EvaluationSuite.load('mathemakitten/sentiment-evaluation-suite')\n",
        "results = suite.run(\"huggingface/Realgon/left_padding50_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EvaluationModule(name: \"accuracy\", module_type: \"metric\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n",
              "Args:\n",
              "    predictions (`list` of `int`): Predicted labels.\n",
              "    references (`list` of `int`): Ground truth labels.\n",
              "    normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.\n",
              "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n",
              "\n",
              "Returns:\n",
              "    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.\n",
              "\n",
              "Examples:\n",
              "\n",
              "    Example 1-A simple example\n",
              "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
              "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])\n",
              "        >>> print(results)\n",
              "        {'accuracy': 0.5}\n",
              "\n",
              "    Example 2-The same as Example 1, except with `normalize` set to `False`.\n",
              "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
              "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)\n",
              "        >>> print(results)\n",
              "        {'accuracy': 3.0}\n",
              "\n",
              "    Example 3-The same as Example 1, except with `sample_weight` set.\n",
              "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
              "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])\n",
              "        >>> print(results)\n",
              "        {'accuracy': 0.8778625954198473}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"Realgon/left_padding50_model\")\n",
        "data = load_dataset(\"imdb\", split=\"test\").shuffle().select(range(1000))\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDTOlZRYNoq2"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "[Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) applies dynamic padding by default when you pass `tokenizer` to it. In this case, you don't need to specify a data collator explicitly.\n",
        "\n",
        "</Tip>\n",
        "\n",
        "Once training is completed, share your model to the Hub with the [push_to_hub()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) method so everyone can use your model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U3P2RFANoq3"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "For a more in-depth example of how to finetune a model for text classification, take a look at the corresponding\n",
        "[PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)\n",
        "or [TensorFlow notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb).\n",
        "\n",
        "</Tip>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJEhPVGRNoq3"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzESQhAwNoq3"
      },
      "source": [
        "Great, now that you've finetuned a model, you can use it for inference!\n",
        "\n",
        "Grab some text you'd like to run inference on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "o28i4HbqNoq3"
      },
      "outputs": [],
      "source": [
        "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aORjdOjPNoq7"
      },
      "source": [
        "The simplest way to try out your finetuned model for inference is to use it in a [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline). Instantiate a `pipeline` for sentiment analysis with your model, and pass your text to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9963740706443787}]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"Realgon/left_padding50_model\")\n",
        "classifier(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'TextClassificationPipeline' object has no attribute 'state'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\wyzhw\\Documents\\GitHub\\Bert_test\\bert_padding_test.ipynb ÂçïÂÖÉÊ†º 61\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wyzhw/Documents/GitHub/Bert_test/bert_padding_test.ipynb#Y136sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39mlog_history\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'TextClassificationPipeline' object has no attribute 'state'"
          ]
        }
      ],
      "source": [
        "classifier.state.log_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmv4KpQWNoq7"
      },
      "source": [
        "You can also manually replicate the results of the `pipeline` if you'd like:\n",
        "\n",
        "Tokenize the text and return PyTorch tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ewWH7KGiNoq7"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Realgon/left_padding50_model\")\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tihdqbqtNoq8"
      },
      "source": [
        "Pass your inputs to the model and return the `logits`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wjHYsNCwNoq8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"Realgon/left_padding50_model\")\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33nOlDGdNoq8"
      },
      "source": [
        "Get the class with the highest probability, and use the model's `id2label` mapping to convert it to a text label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ENptObcoNoq8",
        "outputId": "29db9567-8c48-4842-ba9d-a511a7842ce5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_class_id = logits.argmax().item()\n",
        "model.config.id2label[predicted_class_id]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
